### CSCR3207 Assignment

Submitted By: Ayush Khati (2023414382)

# **Ayush Khati**

### **2023414382**

# **IMDB Movie Review Sentiment Analysis â€” Capstone Project**

This project performs **Sentiment Analysis** on the IMDB 50K Movie Review dataset using three different NLP & ML/AI approaches:

- **TF-IDF + Logistic Regression** (Classic ML)
- **Word2Vec + Logistic Regression** (Embedding-based NLP)
- **DistilBERT Transformer Model** (Modern Gen-AI / LLM technique)

The goal is to compare these approaches in terms of **accuracy, efficiency, and performance**, and understand how traditional NLP compares with modern LLM-based models.

---

## **Project Objectives**

- Analyze the IMDB dataset to classify reviews into **positive** or **negative**.
- Apply different NLP techniques:
  - TF-IDF (Bag of Words)
  - Word2Vec
  - Transformer-based model (DistilBERT)
- Compare all models on:
  - Accuracy
  - Precision, Recall, F1-score
  - Inference time
- Evaluate results and understand:
  - Bias
  - Model limitations
  - Areas for improvement
- Learn practical implementation of Gen-AI and LLM models aligned with the university curriculum.

---

## **Project Structure**

Capstone-Project/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ splits/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ val.csv
â”‚ â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ models/ â† (Ignored using .gitignore)
â”‚
â”œâ”€â”€ notebooks/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ models_bow.py
â”‚ â”œâ”€â”€ models_w2v.py
â”‚ â”œâ”€â”€ train_transformer.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## **Preprocessing Pipeline**

- Remove HTML tags
- Convert to lowercase
- Remove special characters
- Normalize whitespace
- Train/Validation/Test split (80/10/10)

---

# **Models Implemented**

---

## 1 **TF-IDF + Logistic Regression (Bag of Words)**

### Why this works well

Movie reviews contain strong sentiment words (â€œgoodâ€, â€œboringâ€, â€œamazingâ€).  
TF-IDF highlights these.

### **Train**

### **Evaluate**

### âœ” **Results (Your Output)**

- **Accuracy:** 91%
- **Precision/Recall/F1:** ~0.90â€“0.92

---

## 2 **Word2Vec + Logistic Regression**

### âœ” Why slightly less accurate?

Word2Vec captures meaning but **averaging embeddings loses sentiment context**.

### **Train**

### âœ” **Results (Your Output)**

- **Accuracy:** 86%
- **Precision/Recall/F1:** ~0.86

---

## 3ï¸ **DistilBERT Transformer Model (LLM)**

The most modern Gen-AI approach.  
BERT understands **full sentence context** â†’ better sentiment detection.

### ğŸ”§ **Train**

### âœ” **Expected Results**

- **Accuracy:** 92â€“94%
- **Most accurate model overall**

---

# **Final Model Comparison**

| Model                              | Accuracy  | Speed   | Notes                              |
| ---------------------------------- | --------- | ------- | ---------------------------------- |
| **TF-IDF + Logistic Regression**   | â­ 91%    | Fastest | Best classical model               |
| **Word2Vec + Logistic Regression** | 86%       | Fast    | Loses context                      |
| **DistilBERT**                     | â­ 92â€“94% | Slowest | Most accurate, understands context |

# **How to Run the Project**

### Install dependencies:

python src/models_bow.py
python src/models_w2v.py
python src/train_transformer.py
python src/evaluate.py

# **Important: .gitignore Configuration**

Your project ignores large model files to prevent Git/GitHub push errors:
models/
_.joblib
_.model
_.bin
_.pt
\*.pth

This keeps your repository **clean and small**.

---

# **Conclusion**

This capstone project demonstrates:

âœ” Complete NLP pipeline  
âœ” Use of classical ML and modern AI  
âœ” Clean engineering structure  
âœ” Proper evaluation and comparison  
âœ” Hands-on understanding of LLMs

---

# **Author**

## **Ayush Khati**
